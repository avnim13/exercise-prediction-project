<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>Human Activity Recognition Project Report</title>
</head>
<body>
    <h1>Human Activity Recognition using Sensor Data</h1>
    <h2>Project Summary</h2>
    <p>
        This project uses data from accelerometers on the belt, forearm, arm, and dumbbell of 6 participants to predict the manner (quality) in which exercises were performed. The outcome variable "classe" categorizes the performance type, and all other variables are available as predictors. The analysis below describes preprocessing, modeling with Random Forest, cross-validation, and final predictions for the quiz/test set.
    </p>

    <h2>Methodology</h2>
    <ol>
        <li>Loaded the training and test datasets.</li>
        <li>Dropped irrelevant identifier columns and columns with all missing values.</li>
        <li>Aligned feature columns between train and test sets.</li>
        <li>Imputed missing values using mean imputation.</li>
        <li>Trained a Random Forest classifier and performed 5-fold cross-validation for accuracy.</li>
        <li>Predicted exercise manner for the 20 test cases provided.</li>
    </ol>

    <h2>Python Code Used</h2>
    <pre>
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn.impute import SimpleImputer

# Load datasets
train = pd.read_csv('pml-training.csv')
test = pd.read_csv('pml-testing.csv')
cols_to_drop = ['Unnamed: 0', 'user_name', 'raw_timestamp_part_1', 'raw_timestamp_part_2',
                'cvtd_timestamp', 'new_window', 'num_window', 'problem_id']
train.replace('#DIV/0!', np.nan, inplace=True)
test.replace('#DIV/0!', np.nan, inplace=True)
train.drop([c for c in cols_to_drop if c in train.columns], axis=1, inplace=True)
test.drop([c for c in cols_to_drop if c in test.columns], axis=1, inplace=True)
for df in [train, test]:
    na_cols = df.columns[df.isnull().all()]
    df.drop(na_cols, axis=1, inplace=True)
feature_cols = [c for c in train.columns if c in test.columns and c != 'classe']
X = train[feature_cols]
y = train['classe']
test_X = test[feature_cols]
imp = SimpleImputer(strategy='mean')
X_imp = pd.DataFrame(imp.fit_transform(X), columns=feature_cols)
test_X_imp = pd.DataFrame(imp.transform(test_X), columns=feature_cols)
clf = RandomForestClassifier(n_estimators=100, random_state=42)
cv_scores = cross_val_score(clf, X_imp, y, cv=5, scoring='accuracy')
expected_oos_error = 1 - np.mean(cv_scores)
clf.fit(X_imp, y)
test_preds = clf.predict(test_X_imp)
print('Cross-validation accuracy:', np.mean(cv_scores))
print('Expected out of sample error:', expected_oos_error)
print('Predictions for 20 test cases:', list(test_preds))
    </pre>

    <h2>Results</h2>
    <ul>
        <li><b>Cross-validation accuracy:</b> 0.99</li>
        <li><b>Expected out of sample error:</b> 0.01</li>
        <li><b>Predicted classes for the 20 test cases:</b> ['B', 'A', 'B', 'A', 'A', 'E', 'D', 'B', 'A', 'A', 'B', 'C', 'B', 'A', 'E', 'E', 'A', 'B', 'B', 'B']</li>
    </ul>

    <h2>Discussion</h2>
    <p>
        The Random Forest algorithm was chosen for its strong performance on classification tasks with many features, robustness to overfitting through ensemble averaging, and ability to handle non-linear relationships. 5-fold cross-validation provided a reliable estimate of model accuracy and expected real-world error.
    </p>
    <p>
        All results are reproducible using the code above. For peer review, please access this file and accompanying source notebook/code via the provided GitHub repository link.
    </p>
</body>
</html>
